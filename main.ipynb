{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"C:\\\\Users\\\\batuy\\\\Documents\\\\VS Code\\\\animal-classification-app-flask\\\\Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "data_dir = target_path\n",
    "train_dir = \"train_data\"\n",
    "test_dir = \"test_data\"\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her bir kategori için veri ayırma işlemi\n",
    "for category in os.listdir(data_dir):\n",
    "    category_path = os.path.join(data_dir, category)\n",
    "    if os.path.isdir(category_path):\n",
    "        \n",
    "        files = os.listdir(category_path)\n",
    "        train_files, test_files = train_test_split(files, test_size=0.2, random_state=42)\n",
    "        \n",
    "        train_category_dir = os.path.join(train_dir, category)\n",
    "        test_category_dir = os.path.join(test_dir, category)\n",
    "        \n",
    "        os.makedirs(train_category_dir, exist_ok=True)\n",
    "        os.makedirs(test_category_dir, exist_ok=True)\n",
    "        \n",
    "        for file in train_files:\n",
    "            shutil.copy(os.path.join(category_path, file), os.path.join(train_category_dir, file))\n",
    "        \n",
    "        for file in test_files:\n",
    "            shutil.copy(os.path.join(category_path, file), os.path.join(test_category_dir, file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   rotation_range=40,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = train_data_gen.flow_from_directory(directory=\"train_data\", class_mode=\"categorical\", batch_size=64, target_size=img_size)\n",
    "\n",
    "test_d = test_data_gen.flow_from_directory(directory=\"train_data\", class_mode=\"categorical\", batch_size=64, target_size=img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (2, 2), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(32, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rlp = ReduceLROnPlateau(monitor='val_accuracy', factor=0.3, min_lr=0.000001, patience=2)\n",
    "model_check = ModelCheckpoint(filepath=\"project.keras\", monitor=\"val_loss\", verbose=1 ,save_best_only=True)\n",
    "early_ = EarlyStopping(monitor=\"val_loss\",\n",
    "                        min_delta=0.2,\n",
    "                        patience=10,\n",
    "                        verbose=1,\n",
    "                        mode=\"auto\",\n",
    "                        baseline=None,\n",
    "                        restore_best_weights=False,\n",
    "                        start_from_epoch=0,)\n",
    "\n",
    "\n",
    "callbacks = [rlp, early_, model_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_d, validation_data=test_d, batch_size=32, epochs=25, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = load_model(\"project.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model_2.evaluate(test_d)\n",
    "print(f\"loss: {loss}, accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Kayıtlı modeli yükle\n",
    "model = load_model(\"project.keras\")\n",
    "\n",
    "# Test edilecek görüntü dosyasının yolu\n",
    "img_path = \"C:\\\\Users\\\\batuy\\\\Documents\\\\VS Code\\\\animal-classification-app-flask\\\\test_data\\\\Elephant\\\\Elephant_91.jpg\"  # Test edilecek görüntü dosyasının yolunu belirtin\n",
    "\n",
    "# Görüntüyü modelin giriş şekline uygun olarak yükle ve ön işleme yap\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0  # Normalizasyon\n",
    "\n",
    "# Tahmin yap\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Sınıf adlarını belirleyin (modelinize göre güncelleyin)\n",
    "class_names = [\"Buffalo\", \"zebra\", \"Elephant\", \"Rhino\"]  # Örnek: ['cats', 'dogs', 'horses']\n",
    "\n",
    "# Tahmin sonucunu görselleştirme\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img, cmap=plt.cm.binary)\n",
    "plt.axis('off')\n",
    "\n",
    "predicted_class = np.argmax(predictions)\n",
    "confidence = np.max(predictions) * 100\n",
    "class_label = class_names[predicted_class]\n",
    "\n",
    "plt.title(f\"Predicted: {class_label}\\nConfidence: {confidence:.2f}%\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(class_names, predictions.reshape(-1))\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Class Probabilities')\n",
    "plt.ylim([0, 1])\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
